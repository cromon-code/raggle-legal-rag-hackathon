{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base Code\n",
    "4. データの読み込み\n",
    "5. データのインデックス化\n",
    "6. 質問に対する類似情報の検索\n",
    "7. 回答の生成"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters\n",
    "```python\n",
    "pdf_file_urls: list\n",
    "model: str\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"gpt-4o-mini\"\n",
    "pdf_file_urls = [\n",
    "    \"https://storage.googleapis.com/gg-raggle-public/competitions/29676d73-5675-4278-b1a6-d4a9fdd0a0ba/dataset/Architectural_Design_Service_Contract.pdf\",\n",
    "    \"https://storage.googleapis.com/gg-raggle-public/competitions/29676d73-5675-4278-b1a6-d4a9fdd0a0ba/dataset/Call_Center_Operation_Service_Contract.pdf\",\n",
    "    \"https://storage.googleapis.com/gg-raggle-public/competitions/29676d73-5675-4278-b1a6-d4a9fdd0a0ba/dataset/Consulting_Service_Contract.pdf\",\n",
    "    \"https://storage.googleapis.com/gg-raggle-public/competitions/29676d73-5675-4278-b1a6-d4a9fdd0a0ba/dataset/Content_Production_Service_Contract_(Request_Form).pdf\",\n",
    "    \"https://storage.googleapis.com/gg-raggle-public/competitions/29676d73-5675-4278-b1a6-d4a9fdd0a0ba/dataset/Customer_Referral_Contract.pdf\",\n",
    "    \"https://storage.googleapis.com/gg-raggle-public/competitions/29676d73-5675-4278-b1a6-d4a9fdd0a0ba/dataset/Draft_Editing_Service_Contract.pdf\",\n",
    "    \"https://storage.googleapis.com/gg-raggle-public/competitions/29676d73-5675-4278-b1a6-d4a9fdd0a0ba/dataset/Graphic_Design_Production_Service_Contract.pdf\",\n",
    "    \"https://storage.googleapis.com/gg-raggle-public/competitions/29676d73-5675-4278-b1a6-d4a9fdd0a0ba/dataset/M&A_Advisory_Service_Contract_(Preparatory_Committee).pdf\",\n",
    "    \"https://storage.googleapis.com/gg-raggle-public/competitions/29676d73-5675-4278-b1a6-d4a9fdd0a0ba/dataset/M&A_Intermediary_Service_Contract_SME_M&A_[Small_and_Medium_Enterprises].pdf\",\n",
    "    \"https://storage.googleapis.com/gg-raggle-public/competitions/29676d73-5675-4278-b1a6-d4a9fdd0a0ba/dataset/Manufacturing_Sales_Post-Safety_Management_Contract.pdf\",\n",
    "    \"https://storage.googleapis.com/gg-raggle-public/competitions/29676d73-5675-4278-b1a6-d4a9fdd0a0ba/dataset/software_development_outsourcing_contracts.pdf\",\n",
    "    \"https://storage.googleapis.com/gg-raggle-public/competitions/29676d73-5675-4278-b1a6-d4a9fdd0a0ba/dataset/Technical_Verification_(PoC)_Contract.pdf\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data\n",
    "- urlリストからPDFファイルをダウンロードし、Documentオブジェクトのリストとして読み込む\n",
    "\n",
    "```python\n",
    "def download_and_load_pdfs(urls: list) -> list\n",
    "    ...\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_and_load_pdfs(urls: list) -> list:\n",
    "    \"\"\"\n",
    "    PDFファイルをダウンロードして読み込む関数\n",
    "\n",
    "    Args:\n",
    "        urls (list): PDFファイルのURLリスト\n",
    "\n",
    "    Returns:\n",
    "        documents (list): PDFファイルのテキストデータを含むDocumentオブジェクトのリスト\n",
    "\n",
    "    Raises:\n",
    "        Exception: ダウンロードまたは読み込みに失敗した場合に発生する例外\n",
    "\n",
    "    Examples:\n",
    "        >>> urls = [\"https://example.com/example.pdf\"]\n",
    "        >>> download_and_load_pdfs(urls)\n",
    "        [Document(page_content=\"...\", metadata={\"source\": \"https://example.com/example.pdf\"})]\n",
    "    \"\"\"\n",
    "    try:\n",
    "        def download_pdf(url, save_path):\n",
    "            response = requests.get(url)\n",
    "            if response.status_code == 200:\n",
    "                with open(save_path, 'wb') as f:\n",
    "                    f.write(response.content)\n",
    "            else:\n",
    "                raise Exception(f\"Failed to download {url}\")\n",
    "        documents = []\n",
    "\n",
    "        for i, url in enumerate(urls):\n",
    "            tmp_path = f\"pdf_{i}.pdf\"\n",
    "            download_pdf(url, tmp_path)\n",
    "\n",
    "            with pdfplumber.open(tmp_path) as pdf:\n",
    "                full_text = \"\"\n",
    "                for page in pdf.pages:\n",
    "                    text = page.extract_text()\n",
    "                    if text:\n",
    "                        full_text += text + \"\\n\"\n",
    "\n",
    "                documents.append(\n",
    "                    Document(\n",
    "                        page_content=full_text,\n",
    "                        metadata={\"source\": url}\n",
    "                    )\n",
    "                )\n",
    "        return documents\n",
    "    except Exception as e:\n",
    "        raise Exception(f\"Error reading {url}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### vector store\n",
    "- 読み込んだデータに対して、ベクトル検索をするためにインデックス化を行う\n",
    "\n",
    "```python\n",
    "def create_vectorstore(docs: list) -> Chroma\n",
    "    ...\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vectorstore(docs: list) -> Chroma:\n",
    "    \"\"\"\n",
    "    テキストデータからベクトルストアを生成する関数\n",
    "\n",
    "    Args:\n",
    "        docs (list): Documentオブジェクトのリスト\n",
    "\n",
    "    Returns:\n",
    "        vectorstore (Chroma): ベクトルストア\n",
    "\n",
    "    Raises:\n",
    "        Exception: ベクトルストアの生成に失敗した場合に発生する例外\n",
    "\n",
    "    Examples:\n",
    "        >>> docs = [Document(page_content=\"...\", metadata={\"source\": \"https://example.com/example.pdf\"})]\n",
    "        >>> create_vectorstore(docs)\n",
    "        Chroma(...)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        text_splitter = CharacterTextSplitter(\n",
    "            separator=\"\\n\",\n",
    "            chunk_size=1000,\n",
    "        )\n",
    "        splitted_docs = []\n",
    "        for doc in docs:\n",
    "            chunks = text_splitter.split_text(doc.page_content)\n",
    "            for chunk in chunks:\n",
    "                splitted_docs.append(Document(page_content=chunk, metadata=doc.metadata))\n",
    "\n",
    "        embedding_function = OpenAIEmbeddings()\n",
    "\n",
    "        vectorstore = Chroma.from_documents(\n",
    "            splitted_docs,\n",
    "            embedding_function,\n",
    "        )\n",
    "        return vectorstore\n",
    "    except Exception as e:\n",
    "        raise Exception(f\"Error creating vectorstore: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag_implementation(question: str) -> str:\n",
    "    # 4. データの読み込み\n",
    "    docs = download_and_load_pdfs(pdf_file_urls)\n",
    "\n",
    "    # 5. データのインデックス化\n",
    "    db = create_vectorstore(docs)\n",
    "    \n",
    "    # 6. 質問に対する類似情報の検索\n",
    "    retriever = db.as_retriever()\n",
    "\n",
    "    ### 7. 回答の生成\n",
    "    template = \"\"\"\n",
    "    # ゴール\n",
    "    私は、参考文章と質問を提供します。\n",
    "    あなたは、参考文章に基づいて、質問に対する回答を生成してください。\n",
    "\n",
    "    # 質問\n",
    "    {question}\n",
    "\n",
    "    # 参考文章\n",
    "    {context}\n",
    "    \"\"\"\n",
    "    prompt = ChatPromptTemplate.from_template(template)\n",
    "    chat = ChatOpenAI(model=model)\n",
    "    output_parser = StrOutputParser()\n",
    "    setup_and_retrieval = RunnableParallel(\n",
    "        {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "    )\n",
    "\n",
    "    chain = setup_and_retrieval | prompt | chat | output_parser\n",
    "    answer = chain.invoke(question)\n",
    "    return answer"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
